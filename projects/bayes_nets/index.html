<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Understanding Bayesian Networks | Parth Padalkar</title> <meta name="author" content="Parth Padalkar"> <meta name="description" content="Coding different types of bayes nets and learning their structure and parameters."> <meta name="keywords" content="NeSyFOLD, ML, AL, NLP, XAI"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://petrichor1998.github.io/projects/bayes_nets/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Parth </span>Padalkar</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/Projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Understanding Bayesian Networks</h1> <p class="post-description">Coding different types of bayes nets and learning their structure and parameters.</p> </header> <article> <h2 id="the-coding">The Coding</h2> <p>All the code was written in Python without using any of the pre-existing ML libraries such as tensorflow, sklearn, etc. The code can be found on my <a href="https://github.com/petrichor1998/BayesianNetsProject" rel="external nofollow noopener" target="_blank">GitHub</a>. The following are the highlights of the code:</p> <ol> <li>Implemented the Independent Bayesian networks with the following structure: The Bayesian network has no edges.</li> <li>Learnt the parameters of the independent Bayesian network using the maximum likelihood approach.</li> <li>Implemented Tree Bayesian networks. Used the Chow-Liu algorithm to learn the structure and parameters of the Bayesian network as described by <a href="https://www.jmlr.org/papers/volume1/meila00a/html/" rel="external nofollow noopener" target="_blank">Meila and Jordan</a>.</li> <li>Implemented the Mixtures of Tree Bayesian networks using EM. The model is defined as follows. We have one latent variable having \(k\) values and each mixture component is a Tree Bayesian network. Thus, the distribution over the observed variables, denoted by \(\textbf{X}\) (variables in the data) is given by:</li> </ol> \[P(X = x) = \sum_{i=1}^kp_iT_i(X=x)\] <p>where \(p_i\) is the probability of the i-th mixture component and \(T_i\) is the distribution represented by the i-th Tree Bayesian network.</p> <ol> <li> <p>Learnt the structure and parameters of the model using the EM-algorithm (in the M-step each mixture component is learned using the Chow-Liu algorithm).</p> </li> <li> <p>Implemented the Mixtures of Tree Bayesian networks using Random Forests. The model is defined as above. Learnt the structure and parameters of the model using the following Random-Forests style approach. Given two hyper-parameters \((k, r)\), generate \(k\) sets of Bootstrap samples and learn the \(i\)-th Tree Bayesian network using the \(i\)-th set of the Bootstrap samples by randomly setting exactly \(r\) mutual information scores to 0 (as before use the Chow-Liu algorithm with r mutual information scores set to 0 to learn the structure and parameters of the Tree Bayesian network)</p> </li> </ol> <h2 id="the-experiments">The Experiments</h2> <p>Reported the Test-set Log-Likelihood (LL) score on the 10 datasets as shown in the results below.</p> <div class="row justify-content-sm-center"> <div class="col-sm-20 mt-3"> <figure> <picture> <img src="/assets/img/Projects/bayesnets/exp.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Lr with bernoulli model" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="the-learnings">The Learnings</h2> <p>I like to categorize my learnings into two categories: The Profound and The Subtle. The Profound are the key questions that were answered through this project. The Subtle could be an intuition I had, insight I discovered or a clever python hack I learnt from this project. For example, <code class="language-plaintext highlighter-rouge">print</code> statement has a parameter called <code class="language-plaintext highlighter-rouge">end</code> which can be used to change the default newline character to something else.</p> <h3 id="the-profound">The Profound</h3> <p><strong>Q1. How well does each approach perform?</strong></p> <p><em>Independent Bayesian Networks:</em> This method just assumes that there is no relation between the features and is just solely based on the marginal probabilities of those features. The loglikelihood of the test data for this method is the worst of all the cases for all datasets.</p> <p><em>Chow-Liu Tree:</em> This algorithm performs slightly better than the previous one because the tree that is constructed is based on the mutual information matrix which gives a good measure of the dependence of the factors on each other.</p> <p><em>Mixture of trees using EM:</em> This method performs the best among all methods for all the datasets. The EM algorithm work very well because of the large number of epochs. The values of K[2, 3, 4] were found out by testing on the validation set for each dataset by checking their loglikelihood on the validation set. The values have been input as a dictionary of key value pairs where keys are the dataset name and the values are the K values. The validation set testing code has been commented out.</p> <p><em>Random forest style approach for Mixture of trees:</em> This method gives good likelihood scores too but not as good as the mixture of trees method. The best value for the hyperparameters (K[3, 4], R[5, 6, 7]) were found by testing on the validation set. This algorithm works well because of the bootstrapping.</p> <p><strong>Note:</strong> Another way to set the weight for choosing each mixture model instead of 1/k is weighting them according to the likelihood on the train set. The likelihood values on the train set for each mixture tree was calculated and then normalized to act as weight for the respective tree mixture variables. This gives better performance and makes sense as the mixture tree with more likelihood should have more weight while generating the likelihood of the test set.</p> <h3 id="the-subtle">The Subtle</h3> <ol> <li>It is tricky working with probabilities. Storing the probs in the table is enlightening as there are very few values stored in each conditional probability table for each feature/random variable.</li> <li> <em>Ranking:</em> 1) Mixture of trees using EM 2) Random forest style approach for mixture of trees 3) Chow-Liu trees 4) Independent Bayesian Networks</li> </ol> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Parth Padalkar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>