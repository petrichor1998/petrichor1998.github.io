<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>FOLD vs Decision Tree | Parth Padalkar</title> <meta name="author" content="Parth Padalkar"> <meta name="description" content="A comparison of the classification performance and the idea behind generating rules from the data."> <meta name="keywords" content="NeSyFOLD, ML, AL, NLP, XAI"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://petrichor1998.github.io/blog/2023/FOLDvsDT/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "FOLD vs Decision Tree",
      "description": "A comparison of the classification performance and the idea behind generating rules from the data.",
      "published": "February 16, 2023",
      "authors": [
        {
          "author": "Parth Padalkar",
          "authorURL": "",
          "affiliations": [
            {
              "name": "UT Dallas",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Parth </span>Padalkar</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/Projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>FOLD vs Decision Tree</h1> <p>A comparison of the classification performance and the idea behind generating rules from the data.</p> </d-title> <d-byline></d-byline> <d-article> <p>FOLDR++ <d-cite key="foldr++"></d-cite> and FOLDSE <d-cite key="foldse"></d-cite> both generate a decision list as their output. A decision list which is also called an ordered rule-set is a collection of individual classification rules that collectively for a classifier. The benefit of a decision list is that they are considered more interpretable than the decision tree because of their reduced complexity.Lakkaraju et. al. <d-cite key="decisionsets"></d-cite> introduce decision sets which they claim to be more interpretable than decision lists. They mention some limitations of decision lists such as the later rules in the list can only cover a narrow slice of the feature space. Moreover, the while interpreting the rules for a given decision it can be challenging to follow the path of the decision due to the need for checking every rule before the final rule is reached. They also discuss interpretability and explainability at great length in the paper.</p> <p>Here are the questions I encountered while reading about decision lists, decision trees and decision sets:</p> <p><strong>Q) Is there some optimal way of learning a decision tree?</strong> The authors Bertsimas et. al. <d-cite key="optdecisiontree"></d-cite> use Mixed integer Optimization (MIO) for the learning of a decision tree. They show their method of learning decision trees generates optimal trees and outperforms CART. Looking through the paper it is difficult to understand how they define “optimal” in this context.</p> <p><strong>Q) What are the ways in which optimality is defined?</strong> It could be finding the best hypothesis provably that gives highest accuracy on the test set, or it could be the size of the program. Optimal Classification Trees <d-cite key="optdecisiontree"></d-cite> uses the first definition of optimality. ILASP <d-cite key="ilasp"></d-cite> uses the second definition of optimality. Yu et. al. <d-cite key="optimaldecisionsetsandlistssat"></d-cite> define optimality as having minimum number of literals.</p> <p><strong>Q) Are there any theoretical foundations of a decision-list?</strong> Lot of work is available in this area. Heuristic based approaches include RIPPER and FOLDSE. According to different definitions of optimality, different articles are available. Yu et. al. <d-cite key="optimaldecisionsetsandlistssat"></d-cite> find optimal decision sets and decision lists in terms of the minimum number of literals. They use SAT solvers to find the most optimal decision sets/lists.</p> <p><strong>Q) How does FOLDSE compare against the decision-list generating algorithms?</strong> The only comparison availbale is the one with RIPPER but no details of the experiments are provided in terms of the hyperparameters used for RIPPER or FOLDSE both. Although the rule lists generated by FOLDSE are smaller, there is no explanation given as to why this is observed specially since both RIPPER and FOLDSE use a similar sequential covering algorithm for generating the rule set. A possible explanation could be the Magic GINI Impurity heuristic and what are its effect on RIPPER would be interesting to see. A comparison with other decision-list generating algorithms would be interesting.</p> <p><strong>Q) Are there any theoretical foundations of a decision-set?</strong> The authors of the paper Interpretable Decision Sets: A Joint Framework for Description and Prediction <d-cite key="decisionsets"></d-cite> present an algorithm for generating interpretable decision sets. They claim that as long as certain conditions are met the expressive power of a decision set is equivalent to that of a decision tree. They claim through human evaluation that “humans were three times more accurate given a decision set versus a decision list, and they used 74% fewer words and 71% less time to write their descriptions” They also consider “overlap” as a metric for interpretability. They define it as the number of data points that satisfy multiple rules. Note, FOLDSE does not have any overlap as the examples are removed as they are covered. They define an objective function based on interpretability and accuracy metrics which is non-negetive, non-normal, non-monotone and submodular. Then they use Smooth Local Search (SLS) algorithm to get the optimal desicion set. Because of these properties, the objective can be approximately optimized with theoretical guarantees.</p> <p><strong>Q) What optimality does ILASP talk about?</strong> The ILASP <d-cite key="ilasp"></d-cite> system searches for an optimal program. The authors define optimality as a program that has the <em>least</em> number of literals. They use CLINGO to find the optimal program. This is better than a greedy approach because it is guaranteed to find the optimal program. Hence maybe FOLDSE can be compared against ILASP.</p> <p><strong>Q) What type of algorithm does FOLDSE use in terms of the available literature in learning decision lists?</strong> FOLDSE uses sequential covering to generate the rule lists. It is an algorithm that is widely employed to generate rule lists and is also used in the popular rule learning algorithm RIPPER (Repeated Incremental Pruning to Produce Error Reduction) <d-cite key="interpretablemlbookmolnar"></d-cite>. Johannes Fürnkranz et. al. in their book Foundations of Rule Learning <d-cite key="foundationsofrulelearning"></d-cite> describe in detail various rule learning algorithms and their properties.</p> <p><strong>Q) What are the strengths of FOLDSE?</strong> FOLDSE is faster because of the prefix sum technique. The way the categorical and numerical values are compared could also be a contributing factor to the speed and size of the program generated.</p> <p><a href="#%20(Is%20there%20a%20way%20to%20get%20the%20FOLDSEM%20working%20better%20if%20the%20other%20classes%20are%20not%20eliminated?)">//</a>: # (There can be a final rule added that can serve as a “catch all” rule that the algorithm defaults to in case no other rule)</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Parth Padalkar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>