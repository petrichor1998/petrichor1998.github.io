<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning | Parth Padalkar</title> <meta name="author" content="Parth Padalkar"> <meta name="description" content="Using LLMs for generating rationale for questions via bootstrapping"> <meta name="keywords" content="NeSyFOLD, ML, AL, NLP, XAI"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://petrichor1998.github.io/blog/2023/STaR/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning",
      "description": "Using LLMs for generating rationale for questions via bootstrapping",
      "published": "February 16, 2023",
      "authors": [
        {
          "author": "Parth Padalkar",
          "authorURL": "",
          "affiliations": [
            {
              "name": "UT Dallas",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Parth </span>Padalkar</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/Projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning</h1> <p>Using LLMs for generating rationale for questions via bootstrapping</p> </d-title> <d-byline></d-byline> <d-article> <h1 id="introduction">Introduction</h1> <p>Generating a step-by-step “chain-of-thought rationale” for solving complex reasoning problems has been shown to improve the Large Language Model’s (LLM’s) performance on the task <d-cite key="chain_of_thought"></d-cite>. Figure <a href="#fig:1">1</a> illustrates the approach of using a “chain-of-thought rationale” to solve an arithmetic word problem.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <a name="fig:1"></a> <figure> <picture> <img src="/assets/img/chain_of_thought_prompting.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <p class="text-center"> Figure 1: Illustration of the "chain-of-thought rationale" approach for solving an arithmetic word problem. </p> </div> <p>The paper “STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning” <d-cite key="star_bootstrap_reasoning"></d-cite> addresses the problem of the lack of availability of the rationale in the training data. The authors use GPT-J which is a open-source LLM with 6B parameters. In-Context learning does not give very good performace on complex reasoning tasks. Hence, fine-tuning the LLM on the training data is the only way (currently) to improve the performance of the LLm on the task. However, fine-tuning the LLM on the training data is not possible because the training data does not contain the rationale in most cases.</p> <h1 id="methodology">Methodology</h1> <p>The authors propose a bootstraping approach to generate rationales for the training data. The rationale is generated by the LLM itself as shown in Figure <a href="#fig:2">2</a>. The rationale is generated by the LLM by using the following steps:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <a name="fig:2"></a> <figure> <picture> <img src="/assets/img/bootstrapping_in_star.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <p class="text-center"> Figure 2: Illustration of the STaR algorithm. </p> </div> <ol> <li>The LLM is given a few prompts with the question, rationale and answer.</li> <li>For each example in the training data, the LLM is given the question asked to generate the rationale and the answer.</li> <li>If the answer is correct then the rationale is added to the corresponding example in the training data.</li> <li>If the answer is wrong then the answer is given to the LLM along with the question in the prompt to generate a new rationale and answer. (Rationalize)</li> <li>Filter the examples that the LLm generated correct rationales for based on the ground truth answers.</li> <li>Fine-tune the LLM on the filtered examples.</li> <li>Repeat steps 2-6 until the maximum number of iterations is reached.</li> </ol> <h1 id="results">Results</h1> <p>The authors show that this approach is great for generating rationales from limited training data on a vriety of tasks.</p> <h1 id="pros">Pros</h1> <ol> <li>The approach is effective in generating rationales for complex reasoning tasks.</li> </ol> <h1 id="cons">Cons</h1> <ol> <li>The LLM sometimes generates rationales that are based on why the other answers are incorrect rather than why the correct answer is correct. Which may be due to the rationalization.</li> <li>GPT-3 variants like davinci’s performance is not shown. I think it will be the best among all the LLMs.</li> </ol> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Parth Padalkar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>