@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint, arXiv:1502.04623},
  year={2015},
  url={https://arxiv.org/pdf/1502.04623.pdf}
}
@inproceedings{neurasp,
  title     = {NeurASP: Embracing Neural Networks into Answer Set Programming},
  author    = {Yang, Zhun and Ishay, Adam and Lee, Joohyung},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {1755--1762},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/243},
  url       = {https://doi.org/10.24963/ijcai.2020/243},
}
@inproceedings{deepproblog,
 author = {Manhaeve, Robin and Dumancic, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {DeepProbLog:  Neural Probabilistic Logic Programming},
 url = {https://proceedings.neurips.cc/paper/2018/file/dc5d637ed5e62c36ecb73b654b05ba2a-Paper.pdf},
 volume = {31},
 year = {2018}
}
@article{NeSytaxonomy, title={The Third AI Summer: AAAI Robert S. Engelmore Memorial Lecture}, volume={43}, url={https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/19122}, DOI={10.1002/aaai.12036}, abstractNote={&lt;p&gt;This article summarizes the author’s Robert S. Englemore Memorial Lecture presented at the Thirty-Fourth AAAI Conference on Artificial Intelligence on February 10, 2020. It explores recurring themes in the history of AI, real and imagined dangers from AI, and the future of the field.&lt;/p&gt;}, number={1}, journal={AI Magazine}, author={Kautz, Henry}, year={2022}, month={Mar.}, pages={105-125} }
@misc{star_bootstrap_reasoning,
  doi = {10.48550/ARXIV.2203.14465},

  url = {https://arxiv.org/abs/2203.14465},

  author = {Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah D.},

  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {STaR: Bootstrapping Reasoning With Reasoning},

  publisher = {arXiv},

  year = {2022},

  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{chain_of_thought,
  doi = {10.48550/ARXIV.2201.11903},

  url = {https://arxiv.org/abs/2201.11903},

  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},

  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},

  publisher = {arXiv},

  year = {2022},

  copyright = {Creative Commons Attribution 4.0 International}
}
@inproceedings{decisionsets,
author = {Lakkaraju, Himabindu and Bach, Stephen H. and Leskovec, Jure},
title = {Interpretable Decision Sets: A Joint Framework for Description and Prediction},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939874},
doi = {10.1145/2939672.2939874},
abstract = {One of the most important obstacles to deploying predictive models is the fact that humans do not understand and trust them. Knowing which variables are important in a model's prediction and how they are combined can be very powerful in helping people understand and trust automatic decision making systems.Here we propose interpretable decision sets, a framework for building predictive models that are highly accurate, yet also highly interpretable. Decision sets are sets of independent if-then rules. Because each rule can be applied independently, decision sets are simple, concise, and easily interpretable. We formalize decision set learning through an objective function that simultaneously optimizes accuracy and interpretability of the rules. In particular, our approach learns short, accurate, and non-overlapping rules that cover the whole feature space and pay attention to small but important classes. Moreover, we prove that our objective is a non-monotone submodular function, which we efficiently optimize to find a near-optimal set of rules.Experiments show that interpretable decision sets are as accurate at classification as state-of-the-art machine learning techniques. They are also three times smaller on average than rule-based models learned by other methods. Finally, results of a user study show that people are able to answer multiple-choice questions about the decision boundaries of interpretable decision sets and write descriptions of classes based on them faster and more accurately than with other rule-based models that were designed for interpretability. Overall, our framework provides a new approach to interpretable machine learning that balances accuracy, interpretability, and computational efficiency.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1675–1684},
numpages = {10},
keywords = {decision sets, classification, submodularity, interpretable machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}
@misc{ilasp,
      title={The ILASP system for Inductive Learning of Answer Set Programs},
      author={Mark Law and Alessandra Russo and Krysia Broda},
      year={2020},
      eprint={2005.00904},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{optdecisiontree,
      title={Optimal classification trees},
      author={Dimitris Bertsimas and Jack Dunn},
      year={2017},
      url = {https://doi.org/10.1007/s10994-017-5633-9}
}
@book{interpretablemlbookmolnar,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}
@book{foundationsofrulelearning,
  title      = {Foundations of Rule Learning},
  author     = {Johannes Fürnkranz and Dragan Gamberger and Nada Lavrač},
  year       = {2012},
  url        = {https://doi.org/10.1007/978-3-540-75197-7}
}

@article{optimaldecisionsetsandlistssat,
  title={Learning optimal decision sets and lists with sat},
  author={Yu, Jinqiang and Ignatiev, Alexey and Stuckey, Peter J and Le Bodic, Pierre},
  journal={Journal of Artificial Intelligence Research},
  volume={72},
  pages={1251--1279},
  year={2021},
  url = {https://doi.org/10.1613/jair.1.12719}
}
@inproceedings{eric,
  title={ERIC: Extracting relations inferred from convolutions},
  author={Townsend, Joe and Kasioumis, Theodoros and Inakoshi, Hiroya},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020},
  url = {https://openaccess.thecvf.com/content/ACCV2020/html/Townsend_ERIC_Extracting_Relations_Inferred_from_Convolutions_ACCV_2020_paper.html}
}
@inproceedings{ericAAAIworkshop,
title={On the Explainability of Convolutional Layers for Multi-Class Problems},
author={Joe Townsend and Mateusz Kudla and Agnieszka Raszkowska and Theodoros Kasiousmis},
booktitle={Combining Learning and Reasoning: Programming Languages, Formalisms, and Representations},
year={2022},
url={https://openreview.net/forum?id=jgVpiERy8Q8}
}
@inproceedings{elitebackprop,
  title={Elite BackProp: Training Sparse Interpretable Neurons.},
  author={Kasioumis, Theodoros and Townsend, Joe and Inakoshi, Hiroya},
  year={2021},
  url = {http://lr2020.iit.demokritos.gr/online/IJCLR_2021_paper_28.pdf}
}
@inproceedings{ericmedical,
  title={Extracting Meaningful High-Fidelity Knowledge from Convolutional Neural Networks},
  author={Ngan, Kwun Ho and Garcez, Artur D'Avila and Townsend, Joseph},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--17},
  year={2022},
  url = {https://ieeexplore.ieee.org/abstract/document/9892194},
  organization={IEEE}
}
@article{
roleofindividualunits,
author = {David Bau  and Jun-Yan Zhu  and Hendrik Strobelt  and Agata Lapedriza  and Bolei Zhou  and Antonio Torralba },
title = {Understanding the role of individual units in a deep neural network},
journal = {Proceedings of the National Academy of Sciences},
volume = {117},
number = {48},
pages = {30071-30078},
year = {2020},
doi = {10.1073/pnas.1907375117},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1907375117},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1907375117}
}
@misc{foldse,
      title={FOLD-SE: An Efficient Rule-based Machine Learning Algorithm with Scalable Explainability},
      author={Huaduo Wang and Gopal Gupta},
      year={2023},
      eprint={2208.07912},
      archivePrefix={arXiv},
      url = {https://arxiv.org/abs/2208.07912},
      primaryClass={cs.LG}
}
@misc{foldr++,
      title={FOLD-R++: A Scalable Toolset for Automated Inductive Learning of Default Theories from Mixed Data},
      author={Huaduo Wang and Gopal Gupta},
      year={2022},
      eprint={2110.07843},
      archivePrefix={arXiv},
      url = {https://arxiv.org/abs/2110.07843},
      primaryClass={cs.LG}
}
@inproceedings{problog,
    author = {De Raedt, Luc and Kimmig, Angelika and Toivonen, Hannu},
    title = {ProbLog: A Probabilistic Prolog and Its Application in Link Discovery},
    year = {2007},
    publisher = {Morgan Kaufmann Publishers Inc.},
    url = {https://link.springer.com/article/10.1007/s10994-015-5494-z}
}
@article{scallop,
  title={Scallop: From probabilistic deductive databases to scalable differentiable reasoning},
  author={Huang, Jiani and Li, Ziyang and Chen, Binghong and Samel, Karan and Naik, Mayur and Song, Le and Si, Xujie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25134--25145},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/hash/d367eef13f90793bd8121e2f675f0dc2-Abstract.html},
  year={2021}
}